

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>arctern_pyspark._wrapper_func &mdash; Arctern version : 0.2.0 文档</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script src="../../_static/translations.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> Arctern
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../quick_start/quick_start.html">快速开始</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../feature_description/feature_description.html">功能说明</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_reference/api_reference.html">API 参考</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Arctern</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">模块代码</a> &raquo;</li>
        
      <li>arctern_pyspark._wrapper_func</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>arctern_pyspark._wrapper_func 源代码</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (C) 2019-2020 Zilliz. All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="c1"># pylint: disable=too-many-lines</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;ST_Point&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Intersection&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_IsValid&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_PrecisionReduce&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Equals&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Touches&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Overlaps&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Crosses&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_IsSimple&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_GeometryType&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_MakeValid&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_SimplifyPreserveTopology&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_PolygonFromEnvelope&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Contains&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Intersects&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Within&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Distance&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_DistanceSphere&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Area&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Centroid&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Length&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_HausdorffDistance&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_ConvexHull&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_NPoints&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Envelope&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Buffer&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Union_Aggr&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Envelope_Aggr&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_Transform&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_CurveToLine&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_GeomFromGeoJSON&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_PointFromText&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_PolygonFromText&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_LineStringFromText&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_GeomFromText&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_GeomFromWKT&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_AsText&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ST_AsGeoJSON&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Projection&quot;</span><span class="p">,</span>
    <span class="s2">&quot;TransformAndProjection&quot;</span><span class="p">,</span>
    <span class="s2">&quot;WktToWkb&quot;</span><span class="p">,</span>
    <span class="s2">&quot;WkbToWkt&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">pandas_udf</span><span class="p">,</span> <span class="n">PandasUDFType</span>
<span class="kn">import</span> <span class="nn">arctern</span>

<span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">Projection</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">bottom_geo2</span><span class="p">,</span> <span class="n">top_geo1</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">projection</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">bottom_geo2</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">top_geo1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">height</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">width</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">TransformAndProjection</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">src_rs</span><span class="p">,</span> <span class="n">dst_rs</span><span class="p">,</span> <span class="n">bottom_geo2</span><span class="p">,</span> <span class="n">top_geo1</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">transform_and_projection</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">src_rs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dst_rs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bottom_geo2</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">top_geo1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">height</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">width</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">WktToWkb</span><span class="p">(</span><span class="n">wkts</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">wkt2wkb</span><span class="p">(</span><span class="n">wkts</span><span class="p">)</span>

<span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">WkbToWkt</span><span class="p">(</span><span class="n">wkbs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">wkb2wkt</span><span class="p">(</span><span class="n">wkbs</span><span class="p">)</span>

<div class="viewcode-block" id="ST_PointFromText"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_PointFromText.html#arctern_pyspark._wrapper_func.ST_PointFromText">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_PointFromText</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transform the representation of point from WKT to WKB.</span>

<span class="sd">    :type text: WKT</span>
<span class="sd">    :param text: Point in WKT form.</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Point in WKB form.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT (30 10)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; data_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geos&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; data_df.createOrReplaceTempView(&quot;data&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_PointFromText(geos)) from data&quot;).show(100,0)</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">      |ST_AsText(ST_PointFromText(data))|</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">      |POINT (30 10)                    |</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_GeomFromText</span><span class="p">(</span><span class="n">text</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_PolygonFromText"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_PolygonFromText.html#arctern_pyspark._wrapper_func.ST_PolygonFromText">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_PolygonFromText</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transform the representation of polygon from WKT to WKB.</span>

<span class="sd">    :type text: WKT</span>
<span class="sd">    :param text: Polygon in WKT form.</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Polygon in WKB form.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON ((0 0,0 1,1 1,1 0,0 0))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; data_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geos&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; data_df.createOrReplaceTempView(&quot;data&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_PolygonFromText(geos)) from data&quot;).show(100,0)</span>
<span class="sd">      +-----------------------------------+</span>
<span class="sd">      |ST_AsText(ST_PolygonFromText(data))|</span>
<span class="sd">      +-----------------------------------+</span>
<span class="sd">      |POLYGON ((0 0,0 1,1 1,1 0,0 0))    |</span>
<span class="sd">      +-----------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_GeomFromText</span><span class="p">(</span><span class="n">text</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_LineStringFromText"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_LineStringFromText.html#arctern_pyspark._wrapper_func.ST_LineStringFromText">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_LineStringFromText</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transform the representation of linestring from WKT to WKB.</span>

<span class="sd">    :type text: WKT</span>
<span class="sd">    :param text: Linestring in WKT form.</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Linestring in WKB form.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING (0 0, 0 1, 1 1, 1 0)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; data_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geos&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; data_df.createOrReplaceTempView(&quot;data&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_LineStringFromText(geos)) from data&quot;).show(100,0)</span>
<span class="sd">      +--------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_LineStringFromText(data))|</span>
<span class="sd">      +--------------------------------------+</span>
<span class="sd">      |LINESTRING (0 0, 0 1, 1 1, 1 0)       |</span>
<span class="sd">      +--------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_GeomFromText</span><span class="p">(</span><span class="n">text</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_GeomFromWKT"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_GeomFromWKT.html#arctern_pyspark._wrapper_func.ST_GeomFromWKT">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_GeomFromWKT</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transform the representation of geometry from WKT to WKB.</span>

<span class="sd">    :type text: WKT</span>
<span class="sd">    :param text: Geometry in WKT form.</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Geometry in WKB form.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON ((0 0,0 1,1 1,1 0,0 0))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; data_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geos&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; data_df.createOrReplaceTempView(&quot;data&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_GeomFromWKT(geos)) from data&quot;).show(100,0)</span>
<span class="sd">      +-------------------------------+</span>
<span class="sd">      |ST_AsText(ST_GeomFromWKT(data))|</span>
<span class="sd">      +-------------------------------+</span>
<span class="sd">      |POLYGON ((0 0,0 1,1 1,1 0,0 0))|</span>
<span class="sd">      +-------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_GeomFromText</span><span class="p">(</span><span class="n">text</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_GeomFromText"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_GeomFromText.html#arctern_pyspark._wrapper_func.ST_GeomFromText">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_GeomFromText</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transform the representation of geometry from WKT to WKB.</span>

<span class="sd">    :type text: WKT</span>
<span class="sd">    :param text: Geometry in WKT form.</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Geometry in WKB form.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON ((0 0,0 1,1 1,1 0,0 0))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; data_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geos&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; data_df.createOrReplaceTempView(&quot;data&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_GeomFromText(geos)) from data&quot;).show(100,0)</span>
<span class="sd">      +--------------------------------+</span>
<span class="sd">      |ST_AsText(ST_GeomFromText(geos))|</span>
<span class="sd">      +--------------------------------+</span>
<span class="sd">      |POLYGON ((0 0,0 1,1 1,1 0,0 0)) |</span>
<span class="sd">      +--------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_GeomFromText</span><span class="p">(</span><span class="n">text</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_AsText"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_AsText.html#arctern_pyspark._wrapper_func.ST_AsText">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_AsText</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transform the representation of geometry from WKB to WKT.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry in WKB form.</span>

<span class="sd">    :rtype: WKT</span>
<span class="sd">    :return: Geometry in WKT form.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON ((0 0,0 1,1 1,1 0,0 0))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; data_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geos&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; data_df.createOrReplaceTempView(&quot;data&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_GeomFromText(geos)) from data&quot;).show(100,0)</span>
<span class="sd">      +--------------------------------+</span>
<span class="sd">      |ST_AsText(ST_GeomFromText(geos))|</span>
<span class="sd">      +--------------------------------+</span>
<span class="sd">      |POLYGON ((0 0,0 1,1 1,1 0,0 0)) |</span>
<span class="sd">      +--------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_AsText</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_AsGeoJSON"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_AsGeoJSON.html#arctern_pyspark._wrapper_func.ST_AsGeoJSON">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_AsGeoJSON</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return the GeoJSON representation of the geometry.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry in WKB form.</span>

<span class="sd">    :rtype: string</span>
<span class="sd">    :return: Geometry organized as GeoJSON format.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON ((0 0,0 1,1 1,1 0,0 0))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; data_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geos&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; data_df.createOrReplaceTempView(&quot;data&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsGeoJSON(ST_GeomFromText(geos)) from data&quot;).show(100,0)</span>
<span class="sd">      +------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">      |ST_AsGeoJSON(ST_GeomFromText(geos))                                                                               |</span>
<span class="sd">      +------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">      |{ &quot;type&quot;: &quot;Polygon&quot;, &quot;coordinates&quot;: [ [ [ 0.0, 0.0 ], [ 0.0, 1.0 ], [ 1.0, 1.0 ], [ 1.0, 0.0 ], [ 0.0, 0.0 ] ] ] }|</span>
<span class="sd">      +------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_AsGeoJSON</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Point"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_Point.html#arctern_pyspark._wrapper_func.ST_Point">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Point</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Construct point according to the coordinates.</span>

<span class="sd">    :type x: float</span>
<span class="sd">    :param x: Abscissa of the point.</span>

<span class="sd">    :type y: float</span>
<span class="sd">    :param y: Ordinate of the point.</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Point in WKB form.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; points_data = []</span>
<span class="sd">      &gt;&gt;&gt; points_data.extend([(1,1)])</span>
<span class="sd">      &gt;&gt;&gt; points_df = spark_session.createDataFrame(data=points_data, schema=[&quot;x&quot;, &quot;y&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; points_df.createOrReplaceTempView(&quot;points&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_Point(x, y)) from points&quot;).show(100,0)</span>
<span class="sd">      +-------------------------+</span>
<span class="sd">      |ST_AsText(ST_Point(x, y))|</span>
<span class="sd">      +-------------------------+</span>
<span class="sd">      |POINT (1 1)              |</span>
<span class="sd">      +-------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Point</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_GeomFromGeoJSON"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_GeomFromGeoJSON.html#arctern_pyspark._wrapper_func.ST_GeomFromGeoJSON">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_GeomFromGeoJSON</span><span class="p">(</span><span class="n">json</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Construct geometry from the GeoJSON representation.</span>

<span class="sd">    :type json: string</span>
<span class="sd">    :param json: Geometry in GeoJson format.</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Geometry in WKB form.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&quot;{\&quot;type\&quot;:\&quot;Point\&quot;,\&quot;coordinates\&quot;:[1,2]}&quot;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&quot;{\&quot;type\&quot;:\&quot;LineString\&quot;,\&quot;coordinates\&quot;:[[1,2],[4,5],[7,8]]}&quot;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&quot;{\&quot;type\&quot;:\&quot;Polygon\&quot;,\&quot;coordinates\&quot;:[[[0,0],[0,1],[1,1],[1,0],[0,0]]]}&quot;,)])</span>
<span class="sd">      &gt;&gt;&gt; json_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geos&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; json_df.createOrReplaceTempView(&quot;json&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_GeomFromGeoJSON(geos)) from json&quot;).show(100,0)</span>
<span class="sd">      +-----------------------------------+</span>
<span class="sd">      |ST_AsText(ST_GeomFromGeoJSON(geos))|</span>
<span class="sd">      +-----------------------------------+</span>
<span class="sd">      |POINT (1 2)                        |</span>
<span class="sd">      |LINESTRING (1 2,4 5,7 8)           |</span>
<span class="sd">      |POLYGON ((0 0,0 1,1 1,1 0,0 0))    |</span>
<span class="sd">      +-----------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_GeomFromGeoJSON</span><span class="p">(</span><span class="n">json</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Intersection"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_Intersection.html#arctern_pyspark._wrapper_func.ST_Intersection">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Intersection</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the point set intersection of two geometry objects.</span>

<span class="sd">    :type geo1: WKB</span>
<span class="sd">    :param geo1: Geometry</span>

<span class="sd">    :type geo2: WKB</span>
<span class="sd">    :param geo2: Geometry</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Geometry that represents the point set intersection.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT(0 0)&#39;, &#39;LINESTRING ( 2 0, 0 2 )&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT(0 0)&#39;, &#39;LINESTRING ( 0 0, 2 2 )&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; intersection_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geo1&quot;, &quot;geo2&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; intersection_df.createOrReplaceTempView(&quot;intersection&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_Intersection(ST_GeomFromText(geo1), ST_GeomFromText(geo2))) from intersection&quot;).show(100,0)</span>
<span class="sd">      +-------------------------------------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_Intersection(ST_GeomFromText(geo1), ST_GeomFromText(geo2)))|</span>
<span class="sd">      +-------------------------------------------------------------------------+</span>
<span class="sd">      |GEOMETRYCOLLECTION EMPTY                                                 |</span>
<span class="sd">      |POINT (0 0)                                                              |</span>
<span class="sd">      +-------------------------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Intersection</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_IsValid"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_IsValid.html#arctern_pyspark._wrapper_func.ST_IsValid">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_IsValid</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check if geometry is of valid geometry format.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry</span>

<span class="sd">    :rtype: boolean</span>
<span class="sd">    :return: True if geometry is valid.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; spark_session.conf.set(&quot;spark.sql.execution.arrow.pyspark.enabled&quot;, &quot;true&quot;)</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT (30 10)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT (30 10)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; valid_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; valid_df.createOrReplaceTempView(&quot;valid&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_IsValid(ST_GeomFromText(geos)) from valid&quot;).show(100,0)</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">      |ST_IsValid(ST_GeomFromText(geos))|</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">      |true                             |</span>
<span class="sd">      |true                             |</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_IsValid</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_PrecisionReduce"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_PrecisionReduce.html#arctern_pyspark._wrapper_func.ST_PrecisionReduce">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_PrecisionReduce</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">precision</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    For the coordinates of the geometry, reduce the number of significant digits</span>
<span class="sd">    to the given number. The last decimal place will be rounded.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry</span>

<span class="sd">    :type precision: int</span>
<span class="sd">    :param precision: The number to of ignificant digits.</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Geometry with reduced precision.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT (10.777 11.888)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON ((10.23 11.25,6.0 0.0001,5.7854 8.56542,10.23 11.25))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; precision_reduce_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geos&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; precision_reduce_df.createOrReplaceTempView(&quot;precision_reduce&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_PrecisionReduce(ST_GeomFromText(geos), 4)) from precision_reduce&quot;).show(100,0)</span>
<span class="sd">      +-------------------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_PrecisionReduce(ST_GeomFromText(geos), 4))|</span>
<span class="sd">      +-------------------------------------------------------+</span>
<span class="sd">      |POINT (10.78 11.89)                                    |</span>
<span class="sd">      |POLYGON ((10.23 11.25,6 0,5.785 8.565,10.23 11.25))    |</span>
<span class="sd">      +-------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_PrecisionReduce</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">precision</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></div>

<div class="viewcode-block" id="ST_Equals"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_Equals.html#arctern_pyspark._wrapper_func.ST_Equals">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Equals</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether geometries are &quot;spatially equal&quot;. &quot;Spatially equal&quot; here means two geometries represent</span>
<span class="sd">    the same geometry structure.</span>

<span class="sd">    :type geo1: WKB</span>
<span class="sd">    :param geo1: Geometry</span>

<span class="sd">    :type geo2: WKB</span>
<span class="sd">    :param geo2: Geometry</span>

<span class="sd">    :rtype: boolean</span>
<span class="sd">    :return: True if geometry &quot;geo1&quot; equals geometry &quot;geo2&quot;.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(0 0, 10 10)&#39;, &#39;LINESTRING(0 0, 5 5, 10 10)&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(10 10, 0 0)&#39;, &#39;LINESTRING(0 0, 5 5, 10 10)&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(0 0, 10 10)&#39;, &#39;LINESTRING(0 0, 5 5, 8 5)&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; equals_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geo1&quot;, &quot;geo2&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; equals_df.createOrReplaceTempView(&quot;equals&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_Equals(ST_GeomFromText(geo1), ST_GeomFromText(geo2)) from equals&quot;).show(100,0)</span>
<span class="sd">      +--------------------------------------------------------+</span>
<span class="sd">      |ST_Equals(ST_GeomFromText(geo1), ST_GeomFromText(geo2))|</span>
<span class="sd">      +--------------------------------------------------------+</span>
<span class="sd">      |true                                                    |</span>
<span class="sd">      |true                                                    |</span>
<span class="sd">      |false                                                   |</span>
<span class="sd">      +--------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Equals</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Touches"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_Touches.html#arctern_pyspark._wrapper_func.ST_Touches">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Touches</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether geometries &quot;touch&quot;. &quot;Touch&quot; here means two geometries have common points, and the</span>
<span class="sd">    common points locate only on their boundaries.</span>

<span class="sd">    :type geo1: WKB</span>
<span class="sd">    :param geo1: Geometry</span>

<span class="sd">    :type geo2: WKB</span>
<span class="sd">    :param geo2: Geometry</span>

<span class="sd">    :rtype: boolean</span>
<span class="sd">    :return: True if geometry &quot;geo1&quot; touches geometry &quot;geo2&quot;.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(0 0, 1 1, 0 2)&#39;, &#39;POINT(1 1)&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(0 0, 1 1, 0 2)&#39;, &#39;POINT(0 2)&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; touches_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geo1&quot;, &quot;geo2&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; touches_df.createOrReplaceTempView(&quot;touches&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_Touches(ST_GeomFromText(geo1), ST_GeomFromText(geo2)) from touches&quot;).show(100,0)</span>
<span class="sd">      +---------------------------------------------------------+</span>
<span class="sd">      |ST_Touches(ST_GeomFromText(geo1), ST_GeomFromText(geo2))|</span>
<span class="sd">      +---------------------------------------------------------+</span>
<span class="sd">      |false                                                    |</span>
<span class="sd">      |true                                                     |</span>
<span class="sd">      +---------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Touches</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Overlaps"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_Overlaps.html#arctern_pyspark._wrapper_func.ST_Overlaps">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Overlaps</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether geometries &quot;spatially overlap&quot;. &quot;Spatially overlap&quot; here means two geometries</span>
<span class="sd">    intersect but one does not completely contain another.</span>

<span class="sd">    :type geo1: WKB</span>
<span class="sd">    :param geo1: Geometry</span>

<span class="sd">    :type geo2: WKB</span>
<span class="sd">    :param geo2: Geometry</span>

<span class="sd">    :rtype: boolean</span>
<span class="sd">    :return: True if geometry &quot;geo1&quot; overlap geometry &quot;geo2&quot;.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((1 1, 4 1, 4 5, 1 5, 1 1))&#39;, &#39;POLYGON((3 2, 6 2, 6 6, 3 6, 3 2))&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT(1 0.5)&#39;, &#39;LINESTRING(1 0, 1 1, 3 5)&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; overlaps_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geo1&quot;, &quot;geo2&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; overlaps_df.createOrReplaceTempView(&quot;overlaps&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark.sql(&quot;select ST_Overlaps(ST_GeomFromText(geo1), ST_GeomFromText(geo2)) from overlaps&quot;).show(100,0)</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">      |ST_Overlaps(ST_GeomFromText(geo1), ST_GeomFromText(geo2))|</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">      |true                                                      |</span>
<span class="sd">      |false                                                     |</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Overlaps</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">)</span></div>


<div class="viewcode-block" id="ST_Crosses"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_Crosses.html#arctern_pyspark._wrapper_func.ST_Crosses">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Crosses</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether geometries &quot;spatially cross&quot;. &quot;Spatially cross&quot; here means two geometries have</span>
<span class="sd">    some, but not all interior points in common. The intersection of the interiors of the geometries</span>
<span class="sd">    must not be the empty set and must have a dimensionality less than the maximum dimension of the two</span>
<span class="sd">    input geometries.</span>

<span class="sd">    :type geo1: WKB</span>
<span class="sd">    :param geo1: Geometry</span>

<span class="sd">    :type geo2: WKB</span>
<span class="sd">    :param geo2: Geometry</span>

<span class="sd">    :rtype: boolean</span>
<span class="sd">    :return: True if geometry &quot;geo1&quot; crosses geometry &quot;geo2&quot;.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;MULTIPOINT((1 3), (4 1), (4 3))&#39;, &#39;POLYGON((2 2, 5 2, 5 5, 2 5, 2 2))&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((1 1, 4 1, 4 4, 1 4, 1 1))&#39;, &#39;POLYGON((2 2, 5 2, 5 5, 2 5, 2 2))&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; crosses_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geo1&quot;, &quot;geo2&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; crosses_df.createOrReplaceTempView(&quot;crosses&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_Crosses(ST_GeomFromText(geo1), ST_GeomFromText(geo2)) from crosses&quot;).show(100,0)</span>
<span class="sd">      +---------------------------------------------------------+</span>
<span class="sd">      |ST_Crosses(ST_GeomFromText(geo1), ST_GeomFromText(geo2))|</span>
<span class="sd">      +---------------------------------------------------------+</span>
<span class="sd">      |true                                                     |</span>
<span class="sd">      |false                                                    |</span>
<span class="sd">      +---------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Crosses</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_IsSimple"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_IsSimple.html#arctern_pyspark._wrapper_func.ST_IsSimple">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_IsSimple</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether geometry is &quot;simple&quot;. &quot;Simple&quot; here means that a geometry has no anomalous geometric points</span>
<span class="sd">    such as self intersection or self tangency.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry</span>

<span class="sd">    :rtype: boolean</span>
<span class="sd">    :return: True if geometry is simple.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((1 2, 3 4, 5 6, 1 2))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(1 1,2 2,2 3.5,1 3,1 2,2 1)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT (1 1)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; simple_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; simple_df.createOrReplaceTempView(&quot;simple&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_IsSimple(ST_GeomFromText(geos)) from simple&quot;).show(100,0)</span>
<span class="sd">      +----------------------------------+</span>
<span class="sd">      |ST_IsSimple(ST_GeomFromText(geos))|</span>
<span class="sd">      +----------------------------------+</span>
<span class="sd">      |false                             |</span>
<span class="sd">      |false                             |</span>
<span class="sd">      |true                              |</span>
<span class="sd">      +----------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_IsSimple</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_GeometryType"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_GeometryType.html#arctern_pyspark._wrapper_func.ST_GeometryType">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_GeometryType</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    For each geometry in geometries, return a string that indicates it&#39;s type.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry</span>

<span class="sd">    :rtype: string</span>
<span class="sd">    :return: The type of geometry, e.g., &quot;ST_LINESTRING&quot;, &quot;ST_POLYGON&quot;, &quot;ST_POINT&quot;, &quot;ST_MULTIPOINT&quot;.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(77.29 29.07,77.42 29.26,77.27 29.31,77.29 29.07)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT (30 10)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; geometry_type_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; geometry_type_df.createOrReplaceTempView(&quot;geometry_type&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_GeometryType(ST_GeomFromText(geos)) from geometry_type&quot;).show(100,0)</span>
<span class="sd">      +--------------------------------------+</span>
<span class="sd">      |ST_GeometryType(ST_GeomFromText(geos))|</span>
<span class="sd">      +--------------------------------------+</span>
<span class="sd">      |ST_LINESTRING                         |</span>
<span class="sd">      |ST_POINT                              |</span>
<span class="sd">      +--------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_GeometryType</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_MakeValid"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_MakeValid.html#arctern_pyspark._wrapper_func.ST_MakeValid">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_MakeValid</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a valid representation of the geometry without losing any of the input vertices. If</span>
<span class="sd">    the geometry is already-valid, then nothing will be done.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Geometry if the input geometry is already-valid or can be made valid. Otherwise, NULL.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(0 0, 10 0, 20 0, 20 0, 30 0)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON ((1 5, 1 1, 3 3, 5 3, 7 1, 7 5, 5 3, 3 3, 1 5))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON ((1 1,1 5,3 3))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; make_valid_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; make_valid_df.createOrReplaceTempView(&quot;make_valid&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_MakeValid(ST_GeomFromText(geos))) from make_valid&quot;).show(100,0)</span>
<span class="sd">      +------------------------------------------------------------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_MakeValid(ST_GeomFromText(geos)))                                                  |</span>
<span class="sd">      +------------------------------------------------------------------------------------------------+</span>
<span class="sd">      |LINESTRING (0 0,10 0,20 0,20 0,30 0)                                                            |</span>
<span class="sd">      |GEOMETRYCOLLECTION (MULTIPOLYGON (((3 3,1 1,1 5,3 3)),((5 3,7 5,7 1,5 3))),LINESTRING (3 3,5 3))|</span>
<span class="sd">      |NULL                                                                                            |</span>
<span class="sd">      +------------------------------------------------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_MakeValid</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<span class="c1"># TODO: ST_SimplifyPreserveTopology</span>
<div class="viewcode-block" id="ST_SimplifyPreserveTopology"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_SimplifyPreserveTopology.html#arctern_pyspark._wrapper_func.ST_SimplifyPreserveTopology">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_SimplifyPreserveTopology</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">distance_tolerance</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a &quot;simplified&quot; version of the given geometry using the Douglas-Peucker algorithm.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry</span>

<span class="sd">    :type distance_tolerance: float</span>
<span class="sd">    :param distance_tolerance: The maximum distance between a point on a linestring and a curve.</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Geometry</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(</span>
<span class="sd">          &#39;CIRCULARSTRING (0 0,1 1,2 0)&#39;,</span>
<span class="sd">          )])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(</span>
<span class="sd">          &#39;LINESTRING(250 250, 280 290, 300 230, 340 300, 360 260, 440 310, 470 360, 604 286)&#39;,</span>
<span class="sd">          )])</span>
<span class="sd">      &gt;&gt;&gt; simplify_preserve_topology_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; simplify_preserve_topology_df.createOrReplaceTempView(&quot;simplify_preserve_topology&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_SimplifyPreserveTopology(ST_GeomFromText(geos), 1)) from simplify_preserve_topology&quot;).show(100,0)</span>
<span class="sd">      +----------------------------------------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_SimplifyPreserveTopology(ST_GeomFromText(geos), 10))           |</span>
<span class="sd">      +----------------------------------------------------------------------------+</span>
<span class="sd">      |LINESTRING (0 0,2 0)                                                        |</span>
<span class="sd">      |LINESTRING (250 250,280 290,300 230,340 300,360 260,440 310,470 360,604 286)|</span>
<span class="sd">      +----------------------------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_SimplifyPreserveTopology</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">distance_tolerance</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></div>

<div class="viewcode-block" id="ST_PolygonFromEnvelope"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_PolygonFromEnvelope.html#arctern_pyspark._wrapper_func.ST_PolygonFromEnvelope">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_PolygonFromEnvelope</span><span class="p">(</span><span class="n">min_x</span><span class="p">,</span> <span class="n">min_y</span><span class="p">,</span> <span class="n">max_x</span><span class="p">,</span> <span class="n">max_y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Construct a polygon(rectangle) geometry from arr_min_x, arr_min_y, arr_max_x,</span>
<span class="sd">    arr_max_y. The edges of polygon are parallel to coordinate axis.</span>

<span class="sd">    :type min_x: float</span>
<span class="sd">    :param min_x: The minimum value of x coordinate of the rectangles.</span>

<span class="sd">    :type min_y: float</span>
<span class="sd">    :param min_y: The minimum value of y coordinate of the rectangles.</span>

<span class="sd">    :type max_x: float</span>
<span class="sd">    :param max_x: The maximum value of x coordinate of the rectangles.</span>

<span class="sd">    :type max_y: float</span>
<span class="sd">    :param max_y: The maximum value of y coordinate of the rectangles.</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Geometry</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(1.0, 3.0, 5.0, 7.0)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(2.0, 4.0, 6.0, 8.0)])</span>
<span class="sd">      &gt;&gt;&gt; polygon_from_envelope_df = spark_session.createDataFrame(data=test_data, schema=[&#39;min_x&#39;, &#39;min_y&#39;, &#39;max_x&#39;, &#39;max_y&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; polygon_from_envelope_df.createOrReplaceTempView(&#39;polygon_from_envelope&#39;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_PolygonFromEnvelope(min_x, min_y, max_x, max_y)) from polygon_from_envelope&quot;).show(100,0)</span>
<span class="sd">      +-------------------------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_PolygonFromEnvelope(min_x, min_y, max_x, max_y))|</span>
<span class="sd">      +-------------------------------------------------------------+</span>
<span class="sd">      |POLYGON ((1 3,1 7,5 7,5 3,1 3))                              |</span>
<span class="sd">      |POLYGON ((2 4,2 8,6 8,6 4,2 4))                              |</span>
<span class="sd">      +-------------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_PolygonFromEnvelope</span><span class="p">(</span><span class="n">min_x</span><span class="p">,</span> <span class="n">min_y</span><span class="p">,</span> <span class="n">max_x</span><span class="p">,</span> <span class="n">max_y</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Contains"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_Contains.html#arctern_pyspark._wrapper_func.ST_Contains">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Contains</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether geometry &quot;geo1&quot; contains geometry &quot;geo2&quot;. &quot;geo1 contains geo2&quot; means no points</span>
<span class="sd">    of &quot;geo2&quot; lie in the exterior of &quot;geo1&quot; and at least one point of the interior of &quot;geo2&quot; lies</span>
<span class="sd">    in the interior of &quot;geo1&quot;.</span>

<span class="sd">    :type geo1: WKB</span>
<span class="sd">    :param geo1: Geometry</span>

<span class="sd">    :type geo2: WKB</span>
<span class="sd">    :param geo2: Geometry</span>

<span class="sd">    :rtype: boolean</span>
<span class="sd">    :return: True if geometry &quot;geo1&quot; contains geometry &quot;geo2&quot;.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((-1 3,2 1,0 -3,-1 3))&#39;,&#39;POLYGON((0 2,1 1,0 -1,0 2))&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((0 2,1 1,0 -1,0 2))&#39;,&#39;POLYGON((-1 3,2 1,0 -3,-1 3))&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; contains_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geo1&quot;, &quot;geo2&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; contains_df.createOrReplaceTempView(&quot;contains&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_Contains(ST_GeomFromText(geo1), ST_GeomFromText(geo2)) from contains&quot;).show(100,0)</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">      |ST_Contains(ST_GeomFromText(geo1), ST_GeomFromText(geo2))|</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">      |true                                                      |</span>
<span class="sd">      |false                                                     |</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Contains</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Intersects"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_Intersects.html#arctern_pyspark._wrapper_func.ST_Intersects">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Intersects</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether two geometries intersect (i.e., share any portion of space).</span>

<span class="sd">    :type geo1: WKB</span>
<span class="sd">    :param geo1: Geometry</span>

<span class="sd">    :type geo2: WKB</span>
<span class="sd">    :param geo2: Geometry</span>

<span class="sd">    :rtype: boolean</span>
<span class="sd">    :return: True if geometry &quot;geo1&quot; intersects geometry &quot;geo2&quot;.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT(0 0)&#39;, &#39;LINESTRING ( 0 0, 0 2 )&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT(0 0)&#39;,&#39;LINESTRING ( 2 0, 0 2 )&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; intersects_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geo1&quot;, &quot;geo2&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; intersects_df.createOrReplaceTempView(&quot;intersects&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_Intersects(ST_GeomFromText(geo1), ST_GeomFromText(geo2)) from intersects&quot;).show(100,0)</span>
<span class="sd">      +------------------------------------------------------------+</span>
<span class="sd">      |ST_Intersects(ST_GeomFromText(geo1), ST_GeomFromText(geo2))|</span>
<span class="sd">      +------------------------------------------------------------+</span>
<span class="sd">      |true                                                        |</span>
<span class="sd">      |false                                                       |</span>
<span class="sd">      +------------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Intersects</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Within"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_Within.html#arctern_pyspark._wrapper_func.ST_Within">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;boolean&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Within</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check whether geometry &quot;geo1&quot; is within geometry &quot;geo2&quot;. &quot;geo1 within geo2&quot; means no points of &quot;geo1&quot; lie in the</span>
<span class="sd">    exterior of &quot;geo2&quot; and at least one point of the interior of &quot;geo1&quot; lies in the interior of &quot;geo2&quot;.</span>

<span class="sd">    :type geo1: WKB</span>
<span class="sd">    :param geo1: Geometry</span>

<span class="sd">    :type geo2: WKB</span>
<span class="sd">    :param geo2: Geometry</span>

<span class="sd">    :rtype: boolean</span>
<span class="sd">    :return: True if geometry &quot;geo1&quot; within geometry &quot;geo2&quot;.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((2 2, 7 2, 7 5, 2 5, 2 2))&#39;,&#39;POLYGON((1 1, 8 1, 8 7, 1 7, 1 1))&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((0 2, 5 2, 5 5, 0 5, 0 2))&#39;,&#39;POLYGON((1 1, 8 1, 8 7, 1 7, 1 1))&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; within_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geo1&quot;, &quot;geo2&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; within_df.createOrReplaceTempView(&quot;within&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_Within(ST_GeomFromText(geo1), ST_GeomFromText(geo2)) from within&quot;).show(100,0)</span>
<span class="sd">      +--------------------------------------------------------+</span>
<span class="sd">      |ST_Within(ST_GeomFromText(geo1), ST_GeomFromText(geo2))|</span>
<span class="sd">      +--------------------------------------------------------+</span>
<span class="sd">      |true                                                    |</span>
<span class="sd">      |false                                                   |</span>
<span class="sd">      +--------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Within</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Distance"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_Distance.html#arctern_pyspark._wrapper_func.ST_Distance">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;double&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Distance</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the minimum 2D Cartesian (planar) distance between &quot;geo1&quot; and &quot;geo2&quot;.</span>

<span class="sd">    :type geo1: WKB</span>
<span class="sd">    :param geo1: Geometry</span>

<span class="sd">    :type geo2: WKB</span>
<span class="sd">    :param geo2: Geometry</span>

<span class="sd">    :rtype: float</span>
<span class="sd">    :return: The value that represents the distance between geometry &quot;geo1&quot; and geometry &quot;geo2&quot;.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession .builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((-1 -1,2 2,0 1,-1 -1))&#39;,&#39;POLYGON((5 2,7 4,5 5,5 2))&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT(31.75 31.25)&#39;,&#39;LINESTRING(32 32,32 35,40.5 35,32 35,32 32)&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; distance_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geo1&quot;, &quot;geo2&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; distance_df.createOrReplaceTempView(&quot;distance&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_Distance(ST_GeomFromText(geo1), ST_GeomFromText(geo2)) from distance&quot;).show(100,0)</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">      |ST_Distance(ST_GeomFromText(geo1), ST_GeomFromText(geo2))|</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">      |3                                                         |</span>
<span class="sd">      |0.7905694150420949                                        |</span>
<span class="sd">      +----------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Distance</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_DistanceSphere"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_DistanceSphere.html#arctern_pyspark._wrapper_func.ST_DistanceSphere">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;double&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_DistanceSphere</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns minimum distance in meters between two lon/lat points.Uses a spherical earth</span>
<span class="sd">    and radius derived from the spheroid defined by the SRID.</span>

<span class="sd">    :type geo1: WKB</span>
<span class="sd">    :param geo1: Geometry</span>

<span class="sd">    :type geo2: WKB</span>
<span class="sd">    :param geo2: Geometry</span>

<span class="sd">    :rtype: float</span>
<span class="sd">    :return: The value that represents the distance between geometry &quot;geo1&quot; and geometry &quot;geo2&quot;.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession .builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT(31.75 31.25)&#39;,&#39;POINT(31.75 31.25)&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT(31.75 31.25)&#39;,&#39;POINT(32.75 31.25)&#39;)])</span>
<span class="sd">      &gt;&gt;&gt; distance_sphere_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geo1&quot;, &quot;geo2&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; distance_sphere_df.createOrReplaceTempView(&quot;distance_sphere&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_DistanceSphere(ST_GeomFromText(geo1), ST_GeomFromText(geo2)) from distance_sphere&quot;).show(100,0)</span>
<span class="sd">      +---------------------------------------------------------------+</span>
<span class="sd">      |ST_DistanceSphere(ST_GeomFromText(geo1), ST_GeomFromText(geo2))|</span>
<span class="sd">      +---------------------------------------------------------------+</span>
<span class="sd">      |0.0                                                            |</span>
<span class="sd">      |95088.35938555223                                              |</span>
<span class="sd">      +---------------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_DistanceSphere</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Area"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_Area.html#arctern_pyspark._wrapper_func.ST_Area">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;double&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Area</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the 2D Cartesian (planar) area of geometry.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry</span>

<span class="sd">    :rtype: float</span>
<span class="sd">    :return: The value that represents the area of geometry.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((10 20,10 30,20 30,30 10))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON((10 20,10 40,30 40,40 10))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; area_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; area_df.createOrReplaceTempView(&quot;area&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_Area(ST_GeomFromText(geos)) from area&quot;).show(100,0)</span>
<span class="sd">      +------------------------------+</span>
<span class="sd">      |ST_Area(ST_GeomFromText(geos))|</span>
<span class="sd">      +------------------------------+</span>
<span class="sd">      |200                           |</span>
<span class="sd">      |600                           |</span>
<span class="sd">      +------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Area</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Centroid"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_Centroid.html#arctern_pyspark._wrapper_func.ST_Centroid">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Centroid</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the centroid of geometry.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: The centroid of geometry in WKB form.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;MULTIPOINT ( -1 0, -1 2, -1 3, -1 4, -1 7, 0 1, 0 3, 1 1, 2 0, 6 0, 7 8, 9 8, 10 6 )&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;CIRCULARSTRING(0 2, -1 1,0 0, 0.5 0, 1 0, 2 1, 1 2, 0.5 2, 0 2)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; centroid_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; centroid_df.createOrReplaceTempView(&quot;centroid&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_Centroid(ST_GeomFromText(geos))) from centroid&quot;).show(100,0)</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_Centroid(ST_GeomFromText(geos)))|</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">      |POINT (2.30769230769231 3.30769230769231)    |</span>
<span class="sd">      |POINT (0.5 1.0)                              |</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Centroid</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Length"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_Length.html#arctern_pyspark._wrapper_func.ST_Length">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;double&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Length</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the length of linear geometries.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry</span>

<span class="sd">    :rtype: float</span>
<span class="sd">    :return: The value that represents the length of geometry.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(743238 2967416,743238 2967450,743265 2967450, 743265.625 2967416,743238 2967416)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(-72.1260 42.45, -72.1240 42.45666, -72.123 42.1546)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; length_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; length_df.createOrReplaceTempView(&quot;length&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_Length(ST_GeomFromText(geos)) from length&quot;).show(100,0)</span>
<span class="sd">      +--------------------------------+</span>
<span class="sd">      |ST_Length(ST_GeomFromText(geos))|</span>
<span class="sd">      +--------------------------------+</span>
<span class="sd">      |122.63074400009504              |</span>
<span class="sd">      |0.30901547439030225             |</span>
<span class="sd">      +--------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Length</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_HausdorffDistance"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_HausdorffDistance.html#arctern_pyspark._wrapper_func.ST_HausdorffDistance">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;double&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_HausdorffDistance</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the Hausdorff distance between two geometries, which is a measure of how similar</span>
<span class="sd">    two geometries are.</span>

<span class="sd">    :type geo1: WKB</span>
<span class="sd">    :param geo1: Geometry</span>

<span class="sd">    :type geo2: WKB</span>
<span class="sd">    :param geo2: Geometry</span>

<span class="sd">    :rtype: float</span>
<span class="sd">    :return: The value that represents the hausdorff distance between geo1 and geo2.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&quot;POLYGON((0 0 ,0 1, 1 1, 1 0, 0 0))&quot;, &quot;POLYGON((0 0 ,0 2, 1 1, 1 0, 0 0))&quot;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&quot;POINT(0 0)&quot;, &quot;POINT(0 1)&quot;,)])</span>
<span class="sd">      &gt;&gt;&gt; hausdorff_df = spark_session.createDataFrame(data=test_data, schema=[&quot;geo1&quot;, &quot;geo2&quot;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; hausdorff_df.createOrReplaceTempView(&quot;hausdorff&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_HausdorffDistance(ST_GeomFromText(geo1),ST_GeomFromText(geo2)) from hausdorff&quot;).show(100,0)</span>
<span class="sd">      +-----------------------------------------------------------------+</span>
<span class="sd">      |ST_HausdorffDistance(ST_GeomFromText(geo1),ST_GeomFromText(geo2))|</span>
<span class="sd">      +-----------------------------------------------------------------+</span>
<span class="sd">      |1                                                                |</span>
<span class="sd">      |1                                                                |</span>
<span class="sd">      +-----------------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_HausdorffDistance</span><span class="p">(</span><span class="n">geo1</span><span class="p">,</span> <span class="n">geo2</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_ConvexHull"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_ConvexHull.html#arctern_pyspark._wrapper_func.ST_ConvexHull">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_ConvexHull</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the smallest convex geometry that encloses all geometries in the given geometry.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Geometry</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;GEOMETRYCOLLECTION(POINT(1 1),POINT(0 0))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;GEOMETRYCOLLECTION(LINESTRING(2.5 3,-2 1.5), POLYGON((0 1,1 3,1 -2,0 1)))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; convexhull_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; convexhull_df.createOrReplaceTempView(&quot;convexhull&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_convexhull(ST_GeomFromText(geos))) from convexhull&quot;).show(100,0)</span>
<span class="sd">      +-----------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_convexhull(ST_GeomFromText(geos)))|</span>
<span class="sd">      +-----------------------------------------------+</span>
<span class="sd">      |LINESTRING (1 1,0 0)                           |</span>
<span class="sd">      |POLYGON ((1 -2,-2.0 1.5,1 3,2.5 3.0,1 -2))     |</span>
<span class="sd">      +-----------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_ConvexHull</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_NPoints"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_NPoints.html#arctern_pyspark._wrapper_func.ST_NPoints">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_NPoints</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the number of points for the given geometry.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry</span>

<span class="sd">    :rtype: int</span>
<span class="sd">    :return: The number of points.</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(77.29 29.07,77.42 29.26,77.27 29.31,77.29 29.07)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;LINESTRING(77.29 29.07 1,77.42 29.26 0,77.27 29.31 -1,77.29 29.07 3)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; npoints_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; npoints_df.createOrReplaceTempView(&quot;npoints&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_NPoints(ST_GeomFromText(geos)) from npoints&quot;).show(100,0)</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">      |ST_NPoints(ST_GeomFromText(geos))|</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">      |4                                |</span>
<span class="sd">      |4                                |</span>
<span class="sd">      +---------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_NPoints</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<div class="viewcode-block" id="ST_Envelope"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_Envelope.html#arctern_pyspark._wrapper_func.ST_Envelope">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Envelope</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the double-precision minimum bounding box geometry for the given geometry.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Geometry</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;point (10 10)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;linestring (0 0 , 0 10)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;linestring (0 0 , 10 0)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;linestring (0 0 , 10 10)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;polygon ((0 0, 10 0, 10 10, 0 10, 0 0))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;multipoint (0 0, 10 0, 5 5)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;multilinestring ((0 0, 5 5), (6 6, 6 7, 10 10))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;multipolygon (((0 0, 10 0, 10 10, 0 10, 0 0), (11 11, 20 11, 20 20, 20 11, 11 11)))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; envelope_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; envelope_df.createOrReplaceTempView(&quot;envelope&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_Envelope(ST_GeomFromText(geos))) from envelope&quot;).show(100,0)</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_Envelope(ST_GeomFromText(geos)))|</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">      |POINT (10 10)                                |</span>
<span class="sd">      |LINESTRING (0 0,0 10)                        |</span>
<span class="sd">      |LINESTRING (0 0,10 0)                        |</span>
<span class="sd">      |POLYGON ((0 0,0 10,10 10,10 0,0 0))          |</span>
<span class="sd">      |POLYGON ((0 0,0 10,10 10,10 0,0 0))          |</span>
<span class="sd">      |POLYGON ((0 0,0 5,10 5,10 0,0 0))            |</span>
<span class="sd">      |POLYGON ((0 0,0 10,10 10,10 0,0 0))          |</span>
<span class="sd">      |POLYGON ((0 0,0 20,20 20,20 0,0 0))          |</span>
<span class="sd">      +---------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Envelope</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>

<span class="c1"># TODO: ST_Buffer, how to polymorphicly define the behaviour of spark udf</span>
<div class="viewcode-block" id="ST_Buffer"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_Buffer.html#arctern_pyspark._wrapper_func.ST_Buffer">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Buffer</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">distance</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a geometry that represents all points whose distance from the given geometry is</span>
<span class="sd">    less than or equal to &quot;distance&quot;.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry</span>

<span class="sd">    :type distance: float</span>
<span class="sd">    :param distance: The maximum distance of the returned geometry from the given geometry.</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Geometry</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT (0 1)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; buffer_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; buffer_df.createOrReplaceTempView(&quot;buffer&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_Buffer(ST_GeomFromText(geos), 0)) from buffer&quot;).show(100,0)</span>
<span class="sd">      +----------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_Buffer(ST_GeomFromText(geos), 0))|</span>
<span class="sd">      +----------------------------------------------+</span>
<span class="sd">      |POLYGON EMPTY                                 |</span>
<span class="sd">      +----------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Buffer</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">distance</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></div>

<div class="viewcode-block" id="ST_Union_Aggr"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/aggr/Spark_ST_Union_Aggr.html#arctern_pyspark._wrapper_func.ST_Union_Aggr">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">GROUPED_AGG</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Union_Aggr</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a geometry that represents the union of a set of geometries.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Geometry</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data1 = []</span>
<span class="sd">      &gt;&gt;&gt; test_data1.extend([(&#39;POLYGON ((1 1,1 2,2 2,2 1,1 1))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data1.extend([(&#39;POLYGON ((2 1,3 1,3 2,2 2,2 1))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; union_aggr_df1 = spark_session.createDataFrame(data=test_data1, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; union_aggr_df1.createOrReplaceTempView(&quot;union_aggr1&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_Union_Aggr(ST_GeomFromText(geos))) from union_aggr1&quot;).show(100,0)</span>
<span class="sd">      +-----------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_Union_Aggr(ST_GeomFromText(geos)))|</span>
<span class="sd">      +-----------------------------------------------+</span>
<span class="sd">      |POLYGON ((1 1,1 2,2 2,3 2,3 1,2 1,1 1))        |</span>
<span class="sd">      +-----------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rst</span> <span class="o">=</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Union_Aggr</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">rst</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="ST_Envelope_Aggr"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/aggr/Spark_ST_Envelope_Aggr.html#arctern_pyspark._wrapper_func.ST_Envelope_Aggr">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">GROUPED_AGG</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Envelope_Aggr</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the double-precision minimum bounding box geometry for the union of given geometries.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Geometry</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON ((0 0,4 0,4 4,0 4,0 0))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POLYGON ((5 1,7 1,7 2,5 2,5 1))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; envelope_aggr_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;])</span>
<span class="sd">      &gt;&gt;&gt; envelope_aggr_df.createOrReplaceTempView(&#39;envelope_aggr&#39;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_Envelope_Aggr(ST_GeomFromText(geos))) from envelope_aggr&quot;).show(100,0)</span>
<span class="sd">      +--------------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_Envelope_Aggr(ST_GeomFromText(geos)))|</span>
<span class="sd">      +--------------------------------------------------+</span>
<span class="sd">      |POLYGON ((0 0,0 4,7 4,7 0,0 0))                   |</span>
<span class="sd">      +--------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rst</span> <span class="o">=</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Envelope_Aggr</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">rst</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="ST_Transform"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_Transform.html#arctern_pyspark._wrapper_func.ST_Transform">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_Transform</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">from_srid</span><span class="p">,</span> <span class="n">to_srid</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a new geometry with its coordinates transformed from spatial reference system &quot;src_rs&quot; to a &quot;dst_rs&quot;.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry</span>

<span class="sd">    :type from_srid: string</span>
<span class="sd">    :param from_srid: The current srid of geometries.</span>

<span class="sd">    :type to_srid: string</span>
<span class="sd">    :param to_srid: The target srid of geometries tranfrom to.</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Geometry</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;POINT (10 10)&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; buffer_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; buffer_df.createOrReplaceTempView(&quot;buffer&quot;)</span>
<span class="sd">      &gt;&gt;&gt; spark_session.sql(&quot;select ST_AsText(ST_Transform(ST_GeomFromText(geos), &#39;epsg:4326&#39;, &#39;epsg:3857&#39;)) from buffer&quot;).show(100,0)</span>
<span class="sd">      +------------------------------------------------------------------------+</span>
<span class="sd">      |ST_AsText(ST_Transform(ST_GeomFromText(geos), &#39;epsg:4326&#39;, &#39;epsg:3857&#39;))|</span>
<span class="sd">      +------------------------------------------------------------------------+</span>
<span class="sd">      |POINT (1113194.90793274 1118889.97485796)                               |</span>
<span class="sd">      +------------------------------------------------------------------------+</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_Transform</span><span class="p">(</span><span class="n">geos</span><span class="p">,</span> <span class="n">from_srid</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">to_srid</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></div>

<div class="viewcode-block" id="ST_CurveToLine"><a class="viewcode-back" href="../../hide_source/spark/api/geospatial/function/geospatial/Spark_ST_CurveToLine.html#arctern_pyspark._wrapper_func.ST_CurveToLine">[文档]</a><span class="nd">@pandas_udf</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="n">PandasUDFType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">ST_CurveToLine</span><span class="p">(</span><span class="n">geos</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert curves in a geometry to approximate linear representation, e.g., CIRCULAR STRING to regular LINESTRING, CURVEPOLYGON to POLYGON, and</span>
<span class="sd">    MULTISURFACE to MULTIPOLYGON. Useful for outputting to devices that can&#39;t support</span>
<span class="sd">    CIRCULARSTRING geometry types.</span>

<span class="sd">    :type geos: WKB</span>
<span class="sd">    :param geos: Geometry</span>

<span class="sd">    :rtype: WKB</span>
<span class="sd">    :return: Geometry</span>

<span class="sd">    :example:</span>
<span class="sd">      &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">      &gt;&gt;&gt; from arctern_pyspark import register_funcs</span>
<span class="sd">      &gt;&gt;&gt; spark_session = SparkSession.builder.appName(&quot;Python Arrow-in-Spark example&quot;).getOrCreate()</span>
<span class="sd">      &gt;&gt;&gt; register_funcs(spark_session)</span>
<span class="sd">      &gt;&gt;&gt; test_data = []</span>
<span class="sd">      &gt;&gt;&gt; test_data.extend([(&#39;CURVEPOLYGON(CIRCULARSTRING(0 0, 4 0, 4 4, 0 4, 0 0))&#39;,)])</span>
<span class="sd">      &gt;&gt;&gt; buffer_df = spark_session.createDataFrame(data=test_data, schema=[&#39;geos&#39;]).cache()</span>
<span class="sd">      &gt;&gt;&gt; buffer_df.createOrReplaceTempView(&quot;buffer&quot;)</span>
<span class="sd">      &gt;&gt;&gt; rs=spark_session.sql(&quot;select ST_AsText(ST_CurveToLine(ST_GeomFromText(geos))) from buffer&quot;).collect()</span>
<span class="sd">      &gt;&gt;&gt; assert str(rs[0][0]).startswith(&quot;POLYGON&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">arctern</span><span class="o">.</span><span class="n">ST_CurveToLine</span><span class="p">(</span><span class="n">geos</span><span class="p">)</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, zilliz
      <span class="lastupdated">
        最后更新于 6月 17, 2020.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>